<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>From photons to science</title><link href="http://karenyyng.github.io/" rel="alternate"></link><link href="http://karenyyng.github.io/feeds/high-performance-computing.atom.xml" rel="self"></link><id>http://karenyyng.github.io/</id><updated>2016-03-02T00:00:00-08:00</updated><entry><title>Advanced OpenMP Training at NERSC</title><link href="http://karenyyng.github.io/advanced-openmp-training-at-nersc.html" rel="alternate"></link><updated>2016-03-02T00:00:00-08:00</updated><author><name>K. Y. Ng</name></author><id>tag:karenyyng.github.io,2016-03-02:advanced-openmp-training-at-nersc.html</id><summary type="html">&lt;p&gt;I am very happy to learn more about distributed computing at the NERSC Advanced 
Openmp workshop. &lt;/p&gt;
&lt;h1&gt;Nested parallel region&lt;/h1&gt;
&lt;p&gt;How do you determine if there is enough workload for nested parallelism?&lt;/p&gt;
&lt;h1&gt;Private memory&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;only that thread can see the private memory&lt;/li&gt;
&lt;li&gt;you can &lt;code&gt;flush&lt;/code&gt; the private memory to shared memory - don't use if not
    necessary&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;code&gt;Master&lt;/code&gt; vs &lt;code&gt;Single&lt;/code&gt; thread&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;single&lt;/code&gt; has an barrier &lt;/li&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt; does not have an barrier and guarantees that the &lt;code&gt;0&lt;/code&gt;-th thread is
    executed &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;memory access and affinity&lt;/h1&gt;
&lt;h2&gt;loop parallelization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;false-sharing - memory access across cache-line of cores sharing the same
    memory bus &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;First touch policy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;initialization of memory in each thread &lt;/li&gt;
&lt;li&gt;make sure the same thread uses the same memory &lt;/li&gt;
&lt;li&gt;4 times faster memory access this way &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Get info on system topology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Intel MPI 's &lt;code&gt;cpuinfo&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hwloc's &lt;code&gt;hwloc-ls&lt;/code&gt; tool&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Places and binding policies&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SPREAD&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CLOSE&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;&lt;code&gt;MASTER&lt;/code&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;e.g. 
&lt;em&gt; outer parallelism region - &lt;code&gt;spread&lt;/code&gt;
&lt;/em&gt; inner region - &lt;code&gt;close&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;There are two NUMA domain on Cori node.&lt;/p&gt;
&lt;p&gt;Use OpenMP &lt;code&gt;places&lt;/code&gt; / &lt;code&gt;proc bind&lt;/code&gt; instead of &lt;code&gt;KMP_affinity&lt;/code&gt; if possible.&lt;/p&gt;
&lt;p&gt;Page threshing?!&lt;/p&gt;
&lt;h1&gt;SIMD vectorization&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;simple instruction multiple data (SIMD)&lt;/li&gt;
&lt;li&gt;need &lt;code&gt;-O3&lt;/code&gt; for vectorization to work&lt;/li&gt;
&lt;li&gt;&lt;code&gt;safelen (length)&lt;/code&gt;  - can tell the compiler how much strides it is safe to
    vectorize&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;collapse&lt;/code&gt; can be used for combining doubly / triply nested loop that has
    nothing in between the loops &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;openmp &lt;code&gt;tasks&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;dependencies&lt;/h1&gt;
&lt;p&gt;Task dependencies - it tells the threads 
&lt;code&gt;in&lt;/code&gt; and &lt;code&gt;inout&lt;/code&gt; are the same&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BSC blocked cholesky algorithm uses task parallelism &lt;/li&gt;
&lt;li&gt;OpenMPI is not thread safe.&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>